{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"QlGdyiikAiJL"},"outputs":[],"source":["###CONFIGURAÇÕES INICIAIS###\n","\n","# Instalar as bibliotecas necessárias\n","\n","import os\n","import pandas as pd\n","import holidays\n","from datetime import datetime, timedelta\n","\n","# Caminho para salvar o arquivo no Google Drive\n","file_path = r'C:\\Users\\henri\\OneDrive\\Desktop\\DIVERSOS\\OLIST'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sGHdEVox6MRf"},"outputs":[],"source":["\n","\n","### CRIA DIM_DATA ###\n","\n","\n","# Gerar uma lista de datas de 2015 até hoje + 1 dia\n","end_date = datetime.now() + timedelta(days=1)\n","dates = pd.date_range(start='2015-01-01', end=end_date)\n","\n","# Obter feriados no Brasil\n","br_holidays = holidays.Brazil(years=range(2015, end_date.year + 1))\n","\n","# Criar um DataFrame com as datas\n","df = pd.DataFrame({'dt_data': dates})\n","\n","# Adicionar uma coluna indicando se a data é útil (não é feriado e não é fim de semana)\n","df['dt_util'] = df['dt_data'].apply(lambda x: x not in br_holidays and x.weekday() < 5)\n","\n","# Adicionar colunas de dia da semana, mês/ano, trimestre e ano\n","df['dt_diasemana'] = df['dt_data'].dt.strftime('%A')\n","df['dt_diasemana_ord'] = df['dt_data'].dt.weekday\n","df['dt_mesano'] = df['dt_data'].dt.strftime('%B-%Y')\n","df['dt_mesano_ord'] = df['dt_data'].dt.month + (df['dt_data'].dt.year - 2015) * 12\n","df['dt_trimestre'] = df['dt_data'].dt.to_period('Q').astype(str).str.replace('Q', '-Q')\n","df['dt_trimestre_ord'] = df['dt_data'].dt.quarter + (df['dt_data'].dt.year - 2015) * 4\n","df['dt_ano'] = df['dt_data'].dt.year\n","\n","# Adicionar uma coluna de chave sequencial\n","df['sk_data'] = range(1, len(df) + 1)\n","\n","# Reorganizar as colunas conforme o formato especificado\n","df = df[['dt_util', 'dt_data', 'dt_diasemana', 'dt_diasemana_ord',\n","         'dt_mesano', 'dt_mesano_ord', 'dt_trimestre', 'dt_trimestre_ord', 'dt_ano']]\n","\n","# Exibir as primeiras linhas do DataFrame\n","print(df.head())\n","\n","# Salvar o DataFrame em um arquivo CSV no Google Drive\n","df.to_csv(os.path.join(file_path,'bronze\\dim_data.csv'), index=False)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4146,"status":"ok","timestamp":1719312350977,"user":{"displayName":"Henrique Angar","userId":"04335790350184594038"},"user_tz":180},"id":"vX7CIWSvAyCb"},"outputs":[],"source":["\n","### CRIA PEDIDOS ###\n","\n","pedidos = pd.read_csv(file_path+'/landing/pedidos.csv')\n","clientes = pd.read_csv(file_path+'/landing/clientes.csv')\n","vendedores = pd.read_csv(file_path+'/landing/vendedores.csv')\n","pagamentos = pd.read_csv(file_path+'/landing/pagamentos.csv')\n","dadospedidos = pd.read_csv(file_path+'/landing/dadospedidos.csv')\n","\n","clientes.rename(columns = {'idgeralcliente':'idcliente'}, inplace = True)\n","\n","pedidos = pd.merge(pedidos, dadospedidos, on='idpedido', how='left')\n","pedidos = pd.merge(pedidos, pagamentos, on='idpedido', how='left')\n","pedidos = pd.merge(pedidos, vendedores, on='idvendedor', how='left')\n","pedidos = pd.merge(pedidos, clientes, on='idcliente', how='left')\n","\n","pedidos.to_csv(os.path.join(file_path,'bronze/pedidos.csv'), index=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"XoPIoYzoQ3Pt"},"outputs":[],"source":["###DEMAIS TABELAS###\n","\n","localizacoes = pd.read_csv(file_path+'/landing/geo.csv')\n","produtos = pd.read_csv(file_path+'/landing/dadosprodutos.csv')\n","localizacoes.to_csv(file_path+'/bronze/localizacoes.csv')\n","produtos.to_csv(file_path+'/bronze/produtos.csv')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPjLIz+k0GqDw1wZFAdZyFM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
