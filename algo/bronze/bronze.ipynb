{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QlGdyiikAiJL"},"outputs":[],"source":["###CONFIGURAÇÕES INICIAIS###\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, lit, monotonically_increasing_id, when, date_format\n","from datetime import datetime, timedelta\n","import holidays\n","\n","# Inicializando a sessão do Spark\n","spark = SparkSession.builder \\\n","    .appName(\"Bronze\") \\\n","    .getOrCreate()\n","\n","# Caminho para salvar o arquivo no Google Drive\n","file_path = r'C:\\Users\\yurib\\pjf-engenharia-de-dados\\algo'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### CARREGANDO ARQUIVOS DA LANDING ###\n","\n","# Carregar dados da camada landing para Spark\n","pedidos = spark.read.csv(f\"{file_path}/landing/pedidos.csv\", header=True, inferSchema=True)\n","clientes = spark.read.csv(f\"{file_path}/landing/clientes.csv\", header=True, inferSchema=True)\n","vendedores = spark.read.csv(f\"{file_path}/landing/vendedores.csv\", header=True, inferSchema=True)\n","pagamentos = spark.read.csv(f\"{file_path}/landing/pagamentos.csv\", header=True, inferSchema=True)\n","dadospedidos = spark.read.csv(f\"{file_path}/landing/dadospedidos.csv\", header=True, inferSchema=True)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"sGHdEVox6MRf"},"outputs":[],"source":["### CRIAÇÃO DA DIM_DATA ###\n","\n","# Gerar uma lista de datas de 2015 até hoje + 1 dia\n","end_date = datetime.now() + timedelta(days=1)\n","dates = [(datetime(2015, 1, 1) + timedelta(days=i)).strftime('%Y-%m-%d') for i in range((end_date - datetime(2015, 1, 1)).days + 1)]\n","\n","# Criar DataFrame com Spark\n","df = spark.createDataFrame([(date,) for date in dates], [\"dt_data\"])\n","\n","# Obter feriados no Brasil\n","br_holidays = holidays.Brazil(years=range(2015, end_date.year + 1))\n","br_holidays_set = set([str(date) for date in br_holidays])\n","\n","# Adicionar uma coluna indicando se a data é útil (não é feriado e não é fim de semana)\n","df = df.withColumn('dt_util', (~col('dt_data').isin([lit(holiday) for holiday in br_holidays_set])) & (~dayofweek(col('dt_data')).isin([7, 1])))\n","\n","\n"," Adicionar colunas de dia da semana, mês/ano, trimestre e ano\n","df = df.withColumn('dt_diasemana', date_format('dt_data', 'EEEE')) \\\n","       .withColumn('dt_diasemana_ord', dayofweek(col('dt_data'))) \\\n","       .withColumn('dt_mesano', date_format('dt_data', 'MMMM-yyyy')) \\\n","       .withColumn('dt_mesano_ord', (year('dt_data') - 2015) * 12 + month('dt_data')) \\\n","       .withColumn('dt_trimestre', concat(year('dt_data'), lit('-Q'), quarter('dt_data'))) \\\n","       .withColumn('dt_trimestre_ord', (year('dt_data') - 2015) * 4 + quarter('dt_data')) \\\n","       .withColumn('dt_ano', year('dt_data')) \\\n","       .withColumn('sk_data', monotonically_increasing_id())\n","\n","# Reorganizar as colunas conforme o formato especificado\n","df = df.select('dt_util', 'dt_data', 'dt_diasemana', 'dt_diasemana_ord', 'dt_mesano', 'dt_mesano_ord', 'dt_trimestre', 'dt_trimestre_ord', 'dt_ano', 'sk_data')\n"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":4146,"status":"ok","timestamp":1719312350977,"user":{"displayName":"Henrique Angar","userId":"04335790350184594038"},"user_tz":180},"id":"vX7CIWSvAyCb"},"outputs":[],"source":["### CRIAÇÃO DE PEDIDOS ###\n","\n","# Renomear colunas\n","clientes = clientes.withColumnRenamed('idgeralcliente', 'idcliente')\n","\n","# Realizar merges dos dados de pedidos\n","pedidos = pedidos.join(dadospedidos, on='idpedido', how='left') \\\n","                 .join(pagamentos, on='idpedido', how='left') \\\n","                 .join(vendedores, on='idvendedor', how='left') \\\n","                 .join(clientes, on='idcliente', how='left')\n","\n","# Realizar merge dos produtos com os pedidos\n","pedidos = pedidos.join(produtos, pedidos['idproduto'] == produtos['id_produto'], how='left')"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# Adicionar colunas de chave sequencial\n","produtos = produtos.withColumn('SK_Produto', monotonically_increasing_id())\n","localizacoes = localizacoes.withColumn('SK_Localizacoes', monotonically_increasing_id())\n","pedidos = pedidos.withColumn('SK_Pedidos', monotonically_increasing_id())"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["### SALVANDO EM SPARK NA CAMADA BRONZE ###\n","\n","localizacoes.write.mode('overwrite').saveAsTable('localizacoes')\n","produtos.write.mode('overwrite').saveAsTable('produtos')\n","pedidos.write.mode('overwrite').saveAsTable('pedidos')\n","df.write.mode('overwrite').saveAsTable('dim_data')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Fim da sessão Spark\n","spark.stop()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPjLIz+k0GqDw1wZFAdZyFM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
