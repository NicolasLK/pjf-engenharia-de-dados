{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, when, dayofweek, year, month, quarter\n","from pyspark.sql.types import IntegerType, StringType, StructType, StructField\n","from datetime import datetime, timedelta\n","from dotenv import load_dotenv\n","import os\n","\n","# Carregar variáveis de ambiente do arquivo .env\n","load_dotenv()\n","\n","# Obter as chaves da AWS das variáveis de ambiente\n","aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n","aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n","\n","# Iniciando uma SparkSession com Delta Lake\n","spark = SparkSession.builder \\\n","    .appName(\"BronzeLayer\") \\\n","    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n","    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n","    .getOrCreate()\n","\n","# Adicionando configurações S3 diretamente na sessão Spark\n","spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", aws_access_key_id)\n","spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", aws_secret_access_key)\n","spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n","spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n","\n","# Configurações do bucket S3\n","bronze_bucket = \"s3a://engenharia-dados-satc-bronze-bucket\"\n","silver_bucket = \"s3a://engenharia-dados-satc-silver-bucket\"\n","\n","# Carregar arquivos Delta da camada bronze\n","localizacoes = spark.read.format(\"delta\").load(f'{bronze_bucket}/localizacoes')\n","produtos = spark.read.format(\"delta\").load(f'{bronze_bucket}/dadosprodutos')\n","pedidos = spark.read.format(\"delta\").load(f'{bronze_bucket}/pedidos')\n","clientes = spark.read.format(\"delta\").load(f'{bronze_bucket}/clientes')\n","vendedores = spark.read.format(\"delta\").load(f'{bronze_bucket}/vendedores')\n","pagamentos = spark.read.format(\"delta\").load(f'{bronze_bucket}/pagamentos')\n","dadospedidos = spark.read.format(\"delta\").load(f'{bronze_bucket}/dadospedidos')\n","\n","# Renomear colunas\n","clientes = clientes.withColumnRenamed('idgeralcliente', 'idcliente')\n","produtos = produtos.withColumnRenamed('id_produto', 'idproduto')\n","\n","### CRIA DIM_DATA ###\n","\n","# Gerar uma lista de datas de 2015 até hoje + 1 dia\n","end_date = datetime.now() + timedelta(days=1)\n","dates = [end_date - timedelta(days=x) for x in range((end_date - datetime(2015, 1, 1)).days + 1)]\n","\n","# Criar um DataFrame com as datas\n","schema = StructType([\n","    StructField('dt_data', StringType(), True)\n","])\n","df = spark.createDataFrame([(d.strftime('%Y-%m-%d'),) for d in dates], schema=schema)\n","\n","df = df.withColumn('dt_diasemana', dayofweek(col('dt_data')))\n","df = df.withColumn('dt_diasemana_ord', dayofweek(col('dt_data')))\n","df = df.withColumn('dt_mesano', col('dt_data').substr(0, 7))\n","df = df.withColumn('dt_mesano_ord', (year(col('dt_data')) - 2015) * 12 + month(col('dt_data')))\n","df = df.withColumn('dt_trimestre', quarter(col('dt_data')))\n","df = df.withColumn('dt_trimestre_ord', (year(col('dt_data')) - 2015) * 4 + quarter(col('dt_data')))\n","df = df.withColumn('dt_ano', year(col('dt_data')))\n","df = df.withColumn('sk_data', year(col('dt_data')))\n","\n","# Reorganizar as colunas conforme o formato especificado\n","datas = df.select('sk_data', 'dt_data', 'dt_diasemana', 'dt_diasemana_ord', 'dt_mesano', 'dt_mesano_ord', 'dt_trimestre', 'dt_trimestre_ord', 'dt_ano')\n","\n","### CRIA PEDIDOS ###\n","\n","temp = pedidos.join(dadospedidos, on='idpedido', how='left') \\\n","    .join(pagamentos, on='idpedido', how='left') \\\n","    .join(vendedores, on='idvendedor', how='left') \\\n","    .join(clientes, on='idcliente', how='left') \\\n","    .join(produtos, on='idproduto', how='left')\n","\n","temp.show()\n","temp.filter(temp['cepcliente'].isNotNull()).show()\n","\n","### SALVAR TABELAS NA CAMADA SILVER ###\n","\n","temp.write.format(\"delta\").mode('overwrite').save(f'{silver_bucket}/pedidos')\n","localizacoes.write.format(\"delta\").mode('overwrite').save(f'{silver_bucket}/localizacoes')\n","datas.write.format(\"delta\").mode('overwrite').save(f'{silver_bucket}/dim_data')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPjLIz+k0GqDw1wZFAdZyFM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
